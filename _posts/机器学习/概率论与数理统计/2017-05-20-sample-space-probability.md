---
layout: post
title:  "概率论与数理统计 1. 样本空间和概率"
categories: 概率论与数理统计
tags:  理论
author: Geng
---

* content
{:toc}


## 集合

概率论大量涉及到集合的问题，首先要对集合在概率论中的应用有一个直观的映象。

对于掷骰子的概率问题，借用MIT课件的图（掷两次骰子）：

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/roll.png)






上图左边的是用二维网格表示，右侧用树形图表示。

对于左图，可以很方便的画出某种可能性的区域，比如第一次是2，第二次小于3，并可以在图上清晰的看出这个区域：

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/roll23.png)


对于右图，可以很方便的跟踪某种可能性的过程，比如还是第一次是2，第二次小于3，并可以在图上清晰的看出这个过程：

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/roll23tree.png)

以上是离散的例子，关于连续的例子，画起来稍复杂，但是根据离散的例子，完全可以大致建立起基本的概率的观念了。

## 随机变量
这里强调下随机变量这个东西，它**不是变量**，而**是一个函数**。这里强调下，自己去看书，或者看[维基百科](https://zh.wikipedia.org/zh-hans/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F)。

维基百科的这个配图可以清晰的看出，随机变量是样本空间到实数的映射或者函数：

![](https://upload.wikimedia.org/wikipedia/commons/6/6e/Zufall.png)

## 条件概率
已知部分信息的条件下，判断结果会是什么。这其实就是一个缩小样本空间的问题

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/conditional.png)

看上图，可以理解为在B事件发生的条件下，A事件发生的概率，记为：

$$ P(A|B) $$

那么这个概率应该怎么计算呢？

### 样本空间中的理解
为了计算\\(P(A|B) \\)，我们先用样本空间的概念理解：
> 原本的全局空间，缩小为了B空间，这样就是计算在B空间中，A发生的概率是多少。

我们分两步计算：

* 第一步，空间中\\(P(A\|B)\\)到底是哪里？

由上图可见，B空间中A发生的概率可以对应到全局空间中“A并且B发生的概率”的部分\\(P(AB)\\)：

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/aandb.png)


第二步，进入B空间。我们刚才处于全局空间，但是我们计算的是在B空间的情况，那么这一步就要进入B空间了。

B空间比全局空间要小，进入B空间，相当于视场从远到近的拉近过程，B空间内的一切都变的**更大了**:

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/zoomin.png)

那么，对于B空间内的一个子空间C，我们已经测量了它的体积占B空间的\\(c_b\%\\)。如果B空间占全局空间体积的*b%*，那么C空间在全局空间中的体积占比可以如下计算，也就是需要从B进入全局：\\(c\% = c_b\% \times b\% \\)：

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/abc.png)

反过来，如果我们已知C在全局的体积，然后求C在B中的体积，就应该如下操作，也就是从全局进入B空间：\\(c_b\% = \dfrac {c\%} {b\%} \\)：

上面我们从空间体积的思路对一个子空间在不同父空间中的体积占比有了直观映像，下一步就是把这些体积的直观感受转换为概率。概率可以想象为体积比，一个物体在一个空间中体积占比越大，这个物体越容易被发现，对应的发现它的概率就越大。

### 使用样本空间的概念计算
那么我们通过上面两步来计算\\(P(A\|B) \\)

根据上面第一步分析，可知\\(P(A\|B) \\)在全局空间看就是\\(P(AB)\\)部分。根据上面第二部分析，我们需要进入B空间，在全局空间中发生B的概率为：\\(P(B)\\)。

那么可知：
$$ P(A|B) = \dfrac {P(AB)} {P(B)} $$

上面公式可以理解为：在B空间A的占比就是在全局空间中AB的占比对应在B空间的占比。

这里如果可以很好地建立起概率空间的直觉体系，那么以后接触到全概率还是贝叶斯，就都很轻松了。

## 全概率和贝叶斯
全概率理论和贝叶斯理论都是条件概率的应用，但是因为他们太重要了，所以这里单独说明一下。

### 全概率理论

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/total.png)

看上图来理解，全局空间划分为\\(A_1\\), \\(A_2\\), \\(A_3\\),..., \\(A_n\\)这些子空间，我们想要求阴影区域B的概率（面积）。如果B在各个子空间的面积容易求得的话，那么B的面积完全可以变为B在各个子空间的面积的和。转换为概率公式就变成了：

$$ P(B) = P(A_1)P(B | A_1) + P(A_2)P(B | A_2) + P(A_3) P( B |A_3) $$

我们可以把这种求概率的策略理解为“分而治之”的策略。

### 贝叶斯理论
贝叶斯理论对于很多人来说是神一样的存在，并不是因为这个理论真的是神一样的存在，而是因为很多人不理解什么是贝叶斯理论，但是关于这个理论的新闻和传说倒是看了不少（抱歉把新闻和传说放在一起了，我要对传说说一声抱歉）。

贝叶斯理论其实就是**确定你到底在哪里的过程**。

还是看上面全概率公式的图，我们想要知道自己在**\\(A_3\\)空间的可能性有多大**，在全局空间中，\\(A_3\\)的面积是是\\(P(A_3)\\)。我们**需要更多的证据**来判断我们到底在哪里。

随着证据的增多，我们**观测到B发生了**，B在全局发生的概率为\\(P(B)\\)。那么我们在\\(A_3\\)的可能性因为**有了新的观测数据，需要改写**为：\\(P(A_3 \| B)\\)，也就是在B发生的情况下，我们在\\(A_3\\)空间的可能性。

根据条件概率公式我们可以得出这个计算公式：

$$ P(A_3 | B) = \dfrac {P(A_3B)} {P(B)}$$

然后根据全概率公式，又可以变为：

$$ P(A_3 | B) = \dfrac {P(A_3B)} {P(A_1)P(B | A_1) + P(A_2)P(B | A_2) + P(A_3) P( B |A_3)}$$

最后，也可以把\\(P(A_3 B)\\)也展开：

$$ P(A_3 | B) = \dfrac {P(A_3)P(B|A_3)} {P(A_1)P(B | A_1) + P(A_2)P(B | A_2) + P(A_3) P( B |A_3)}$$

分析上面的过程，最开始的时候，我们没有任何信息，只能在全局空间中判断，得出一个**先验概率**：\\(P(A_3)\\)。

然后因为有了新的信息，我们可以根据新的信息缩小范围，得到一个**后验概率**：\\(P(A_3\| B)\\)。

贴近生活的理解，我们可以将贝叶斯理论理解为如何断案，是一个**推断**的过程。假设你是福尔摩斯，找到了一个命案嫌疑人，他无罪和有罪的概率此时比如是\\(P(凶手) = 0.5\\)，\\(P(不是凶手) = 0.5\\)。

这个时候，你发现嫌疑人进行了一次抢劫，那么此时我们根据新的信息推断，\\(P(凶手 \| 抢劫) = 0.6\\)，\\(P(不是凶手 \| 抢劫) = 0.4\\)。然后根据后续不断地观察，新的信息原来越多，\\(P(凶手 \| （抢劫 \cap 放火 \cap 拐卖) = 0.99\\)，\\(P(不是凶手 \| 抢劫 \cap 放火 \cap 拐卖) = 0.01\\)。

那么此时，根据足够的信息，此人是凶手的概率已经很高，我们有理由相信，他就是凶手。

> 引起一个结果的原因有很多，贝叶斯理论，就是在知道了结果的条件下，去反推到底是什么原因的过程。

#### 使用贝叶斯原理缓解医患矛盾
医生看了能给打赏吗？😆。

假设有一种病，人群的此病的概率是1%，得病的话，99%能检验出来；没病的话，1%误诊。那么如果检测结果有病，一个人实际有病的概率多少呢？从数据上看，好像误诊率很低吧？

我们自己可以根据贝叶斯公式计算，真正的误诊率其实很高。这里我就不计算了，画图说明这个问题：

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/ill.png)

根据上图，很容易看出，就算检测有病，很大可能也是没病的。

## 独立性
这里图示的方法不太好用，但是有一个重点需要强调一下：
* A事件发生与否不能带给我们任何关于B的信息，那么A，B相互独立，也就是\\(P(B\|A) = P(B)\\)。

考虑几个例子：

* 两个事件是互斥事件。既然互斥，那么一个发生，另一个必然不发生。也就是一个发生与否直接给出我们另一个发生与否的信息，所以互斥事件一定不是独立的。

* 条件独立性。看下图，假设全局中，A，B互斥，那么如果得知C事件发生了，A，B还独立吗？在C空间，A，B互斥，所以他们在C空间不独立。

![]({{ site.url }}/assets/images/posts/machineLearning/2017-05-20-sample-space-probability/conditional_independent.png)

* 根据上面例子，我们可以得出另一个小技巧：韦恩图不能看出来是否独立，但是可以看出来不独立。（你能看出来这个小技巧吗？）
